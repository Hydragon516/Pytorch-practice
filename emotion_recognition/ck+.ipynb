{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./ckplus/ck/CK+48\\\\anger', './ckplus/ck/CK+48\\\\contempt', './ckplus/ck/CK+48\\\\disgust', './ckplus/ck/CK+48\\\\fear', './ckplus/ck/CK+48\\\\happy', './ckplus/ck/CK+48\\\\sadness', './ckplus/ck/CK+48\\\\surprise']\n"
     ]
    }
   ],
   "source": [
    "root = glob.glob('./ckplus/ck/CK+48/*')\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(981, 1, 48, 48) (981,)\n"
     ]
    }
   ],
   "source": [
    "img_list = []\n",
    "label_list = []\n",
    "\n",
    "classes = ['anger', 'contempt', 'disgust', 'fear', 'happy', 'sadness', 'surprise']\n",
    "\n",
    "for dirc in root:\n",
    "    emotion = (dirc.split('\\\\'))[1]\n",
    "    \n",
    "    images = glob.glob(dirc + '/*')\n",
    "    for image in images:\n",
    "        img = cv2.imread(image, 0)\n",
    "        img.resize(1, 48, 48)\n",
    "        img = img / 255\n",
    "        img_list.append(img)\n",
    "\n",
    "        label = classes.index(emotion)\n",
    "        label_list.append(label)\n",
    "\n",
    "image = np.array(img_list)\n",
    "label = np.array(label_list)\n",
    "\n",
    "print(image.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train  =  torch.FloatTensor(image)\n",
    "y_train  =  torch.IntTensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(x_train, y_train)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [900, 81])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise sadness anger happy disgust surprise surprise sadness anger surprise disgust sadness happy surprise disgust surprise surprise contempt disgust surprise disgust disgust  fear  fear anger surprise sadness happy anger surprise happy disgust\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=1296, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 9 * 9, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 9 * 9)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.0005\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50 ||  Training Loss: 2.03158 ||  Val Loss: 1.69868  Val ACC : 0.30864\n",
      "Epoch: 2/50 ||  Training Loss: 1.86603 ||  Val Loss: 1.66838  Val ACC : 0.30864\n",
      "Epoch: 3/50 ||  Training Loss: 1.81599 ||  Val Loss: 1.68940  Val ACC : 0.30864\n",
      "Epoch: 4/50 ||  Training Loss: 1.80361 ||  Val Loss: 1.65273  Val ACC : 0.30864\n",
      "Epoch: 5/50 ||  Training Loss: 1.75577 ||  Val Loss: 1.51954  Val ACC : 0.49383\n",
      "Epoch: 6/50 ||  Training Loss: 1.63648 ||  Val Loss: 1.21584  Val ACC : 0.64198\n",
      "Epoch: 7/50 ||  Training Loss: 1.29794 ||  Val Loss: 0.82478  Val ACC : 0.80247\n",
      "Epoch: 8/50 ||  Training Loss: 0.97371 ||  Val Loss: 0.61363  Val ACC : 0.74074\n",
      "Epoch: 9/50 ||  Training Loss: 0.81147 ||  Val Loss: 0.55246  Val ACC : 0.76543\n",
      "Epoch: 10/50 ||  Training Loss: 0.66116 ||  Val Loss: 0.42581  Val ACC : 0.83951\n",
      "Epoch: 11/50 ||  Training Loss: 0.55095 ||  Val Loss: 0.51658  Val ACC : 0.80247\n",
      "Epoch: 12/50 ||  Training Loss: 0.53796 ||  Val Loss: 0.36733  Val ACC : 0.85185\n",
      "Epoch: 13/50 ||  Training Loss: 0.47814 ||  Val Loss: 0.33604  Val ACC : 0.86420\n",
      "Epoch: 14/50 ||  Training Loss: 0.44180 ||  Val Loss: 0.24868  Val ACC : 0.92593\n",
      "Epoch: 15/50 ||  Training Loss: 0.46088 ||  Val Loss: 0.27108  Val ACC : 0.90123\n",
      "Epoch: 16/50 ||  Training Loss: 0.36537 ||  Val Loss: 0.24146  Val ACC : 0.91358\n",
      "Epoch: 17/50 ||  Training Loss: 0.31308 ||  Val Loss: 0.18061  Val ACC : 0.93827\n",
      "Epoch: 18/50 ||  Training Loss: 0.30124 ||  Val Loss: 0.16611  Val ACC : 0.93827\n",
      "Epoch: 19/50 ||  Training Loss: 0.28396 ||  Val Loss: 0.14676  Val ACC : 0.96296\n",
      "Epoch: 20/50 ||  Training Loss: 0.27283 ||  Val Loss: 0.16782  Val ACC : 0.91358\n",
      "Epoch: 21/50 ||  Training Loss: 0.23558 ||  Val Loss: 0.15367  Val ACC : 0.95062\n",
      "Epoch: 22/50 ||  Training Loss: 0.20663 ||  Val Loss: 0.10964  Val ACC : 0.95062\n",
      "Epoch: 23/50 ||  Training Loss: 0.20591 ||  Val Loss: 0.14458  Val ACC : 0.93827\n",
      "Epoch: 24/50 ||  Training Loss: 0.18433 ||  Val Loss: 0.09255  Val ACC : 0.96296\n",
      "Epoch: 25/50 ||  Training Loss: 0.16941 ||  Val Loss: 0.12245  Val ACC : 0.96296\n",
      "Epoch: 26/50 ||  Training Loss: 0.15737 ||  Val Loss: 0.15091  Val ACC : 0.93827\n",
      "Epoch: 27/50 ||  Training Loss: 0.16456 ||  Val Loss: 0.07739  Val ACC : 0.97531\n",
      "Epoch: 28/50 ||  Training Loss: 0.17137 ||  Val Loss: 0.09036  Val ACC : 0.96296\n",
      "Epoch: 29/50 ||  Training Loss: 0.15059 ||  Val Loss: 0.08938  Val ACC : 0.98765\n",
      "Epoch: 30/50 ||  Training Loss: 0.18285 ||  Val Loss: 0.07574  Val ACC : 0.98765\n",
      "Epoch: 31/50 ||  Training Loss: 0.11852 ||  Val Loss: 0.08441  Val ACC : 0.96296\n",
      "Epoch: 32/50 ||  Training Loss: 0.11586 ||  Val Loss: 0.05221  Val ACC : 0.98765\n",
      "Epoch: 33/50 ||  Training Loss: 0.08649 ||  Val Loss: 0.05022  Val ACC : 0.98765\n",
      "Epoch: 34/50 ||  Training Loss: 0.08332 ||  Val Loss: 0.04382  Val ACC : 0.98765\n",
      "Epoch: 35/50 ||  Training Loss: 0.08848 ||  Val Loss: 0.03700  Val ACC : 0.98765\n",
      "Epoch: 36/50 ||  Training Loss: 0.07932 ||  Val Loss: 0.05526  Val ACC : 0.97531\n",
      "Epoch: 37/50 ||  Training Loss: 0.07568 ||  Val Loss: 0.04534  Val ACC : 0.98765\n",
      "Epoch: 38/50 ||  Training Loss: 0.08910 ||  Val Loss: 0.04918  Val ACC : 0.98765\n",
      "Epoch: 39/50 ||  Training Loss: 0.06534 ||  Val Loss: 0.05853  Val ACC : 0.96296\n",
      "Epoch: 40/50 ||  Training Loss: 0.04761 ||  Val Loss: 0.03743  Val ACC : 0.98765\n",
      "Epoch: 41/50 ||  Training Loss: 0.04192 ||  Val Loss: 0.02562  Val ACC : 1.00000\n",
      "Epoch: 42/50 ||  Training Loss: 0.04390 ||  Val Loss: 0.03036  Val ACC : 0.98765\n",
      "Epoch: 43/50 ||  Training Loss: 0.03926 ||  Val Loss: 0.03352  Val ACC : 0.98765\n",
      "Epoch: 44/50 ||  Training Loss: 0.03304 ||  Val Loss: 0.02403  Val ACC : 1.00000\n",
      "Epoch: 45/50 ||  Training Loss: 0.03920 ||  Val Loss: 0.01210  Val ACC : 1.00000\n",
      "Epoch: 46/50 ||  Training Loss: 0.03840 ||  Val Loss: 0.02156  Val ACC : 1.00000\n",
      "Epoch: 47/50 ||  Training Loss: 0.02728 ||  Val Loss: 0.01118  Val ACC : 1.00000\n",
      "Epoch: 48/50 ||  Training Loss: 0.02000 ||  Val Loss: 0.00888  Val ACC : 1.00000\n",
      "Epoch: 49/50 ||  Training Loss: 0.01807 ||  Val Loss: 0.01508  Val ACC : 1.00000\n",
      "Epoch: 50/50 ||  Training Loss: 0.01764 ||  Val Loss: 0.01361  Val ACC : 1.00000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, accuracy = [], [], []\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        labels = labels.long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    else:\n",
    "        val_loss = 0\n",
    "        val_accuracy = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            cnt = 0\n",
    "            \n",
    "            for val_image, val_label in val_loader:\n",
    "                val_image, val_label = val_image.to(device), val_label.to(device)\n",
    "                val_label = val_label.long()\n",
    "                \n",
    "                val_outputs = net(val_image)\n",
    "                _, top_class = val_outputs.topk(1, dim=1)\n",
    "                \n",
    "                if top_class == val_label:\n",
    "                    cnt += 1\n",
    "                \n",
    "                val_loss += criterion(val_outputs, val_label)\n",
    "\n",
    "        acc = cnt / len(val_loader)\n",
    "        \n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        val_losses.append(val_loss/len(val_loader))\n",
    "        accuracy.append(acc)\n",
    "\n",
    "        print(\"Epoch: {}/{} || \".format(epoch+1, epochs),\n",
    "              \"Training Loss: {:.5f} || \".format(running_loss/len(train_loader)),\n",
    "              \"Val Loss: {:.5f} \".format(val_loss/len(val_loader)),\n",
    "              \"Val ACC : {:.5f}\".format(acc)\n",
    "             )\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  happy\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(val_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  happy\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
